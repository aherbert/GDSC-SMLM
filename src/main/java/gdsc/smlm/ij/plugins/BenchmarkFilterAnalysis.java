package gdsc.smlm.ij.plugins;

/*----------------------------------------------------------------------------- 
 * GDSC SMLM Software
 * 
 * Copyright (C) 2013 Alex Herbert
 * Genome Damage and Stability Centre
 * University of Sussex, UK
 * 
 * This program is free software; you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation; either version 3 of the License, or
 * (at your option) any later version.
 *---------------------------------------------------------------------------*/

import gdsc.smlm.fitting.FitResult;
import gdsc.smlm.fitting.FitStatus;
import gdsc.smlm.function.gaussian.Gaussian2DFunction;
import gdsc.smlm.ga.Chromosome;
import gdsc.smlm.ga.ChromosomeComparator;
import gdsc.smlm.ga.FitnessFunction;
import gdsc.smlm.ga.Population;
import gdsc.smlm.ga.RampedSelectionStrategy;
import gdsc.smlm.ga.Recombiner;
import gdsc.smlm.ga.SelectionStrategy;
import gdsc.smlm.ga.SimpleMutator;
import gdsc.smlm.ga.SimpleRecombiner;
import gdsc.smlm.ga.SimpleSelectionStrategy;
import gdsc.smlm.ga.ToleranceChecker;
import gdsc.smlm.ij.plugins.BenchmarkSpotFit.FilterCandidates;
import gdsc.smlm.ij.plugins.BenchmarkSpotFit.SpotMatch;
import gdsc.smlm.ij.settings.FilterSettings;
import gdsc.smlm.ij.settings.GlobalSettings;
import gdsc.smlm.ij.settings.SettingsManager;
import gdsc.smlm.ij.utils.Utils;
import gdsc.smlm.results.Calibration;
import gdsc.smlm.results.MemoryPeakResults;
import gdsc.smlm.results.PeakResult;
import gdsc.smlm.results.TrackProgress;
import gdsc.smlm.results.filter.Filter;
import gdsc.smlm.results.filter.FilterSet;
import gdsc.smlm.results.filter.XStreamWrapper;
import gdsc.smlm.results.match.FractionClassificationResult;
import gdsc.smlm.utils.Maths;
import gdsc.smlm.utils.RampedScore;
import gdsc.smlm.utils.Sort;
import gdsc.smlm.utils.StoredDataStatistics;
import gdsc.smlm.utils.UnicodeReader;
import gdsc.smlm.utils.XmlUtils;
import ij.IJ;
import ij.gui.GenericDialog;
import ij.gui.Plot2;
import ij.gui.PlotWindow;
import ij.plugin.PlugIn;
import ij.plugin.WindowOrganiser;
import ij.text.TextWindow;

import java.awt.Color;
import java.awt.Point;
import java.io.BufferedReader;
import java.io.File;
import java.io.FileInputStream;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.OutputStreamWriter;
import java.math.BigDecimal;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map.Entry;

import org.apache.commons.math3.analysis.interpolation.LinearInterpolator;
import org.apache.commons.math3.analysis.interpolation.LoessInterpolator;
import org.apache.commons.math3.analysis.polynomials.PolynomialSplineFunction;
import org.apache.commons.math3.random.RandomDataGenerator;
import org.apache.commons.math3.random.Well44497b;

/**
 * Run different filtering methods on a set of benchmark fitting results outputting performance statistics on the
 * success of the filter. The fitting results are generated by the BenchmarkSpotFit plugin.
 * <p>
 * Filtering is done using e.g. SNR threshold, Precision thresholds, etc. The statistics reported are shown in a table,
 * e.g. precision, Jaccard, F-score.
 */
public class BenchmarkFilterAnalysis implements PlugIn, FitnessFunction, TrackProgress
{
	private static final String TITLE = "Filter Analysis";
	private static TextWindow resultsWindow = null;
	private static TextWindow summaryWindow = null;
	private static TextWindow sensitivityWindow = null;
	private static TextWindow gaWindow = null;

	private static int failCount = 1;
	private static int failCountRange = 0;
	private static boolean rerankBySignal = false;
	private static boolean showResultsTable = false;
	private static boolean showSummaryTable = true;
	private static boolean clearTables = false;
	private static String filterFilename = "";
	private static String filterSetFilename = "";
	private static int summaryTopN = 0;
	private static double summaryDepth = 500;
	private static int plotTopN = 0;
	private static boolean saveBestFilter = false;
	private ArrayList<NamedPlot> plots;
	private static boolean calculateSensitivity = false;
	private static double delta = 0.1;
	private static int criteriaIndex;
	private static double criteriaLimit = 0.95;
	private double minCriteria = 0;
	private boolean invertCriteria = false;
	private static int scoreIndex;
	private boolean invertScore = false;
	private static double upperMatchDistance = 100;
	private static double partialMatchDistance = 33;
	private static double upperSignalFactor = 100;
	private static double partialSignalFactor = 50;
	private static boolean depthRecallAnalysis = true;
	private static boolean evolve = false;

	private static int populationSize = 500;
	private static int failureLimit = 5;
	private static double tolerance = 1e-4;
	private static int convergedCount = 2;
	private static double crossoverRate = 1;
	private static double meanChildren = 2;
	private static double mutationRate = 1;
	private static double selectionFraction = 0.2;
	private static boolean rampedSelection = true;
	private static boolean strictFitness = true;
	private static boolean saveOption = false;

	private static String resultsTitle;
	private String resultsPrefix, resultsPrefix2;
	private static String resultsPrefix3;

	private HashMap<String, FilterScore> bestFilter;
	private LinkedList<String> bestFilterOrder;

	private static boolean reUseFilters = true;
	private static boolean expandFilters = true;
	private static String oldFilename = "";
	private static long lastModified = 0;
	private static List<FilterSet> filterList = null;
	private static boolean[][] wasNotExpanded;
	private static double[][] lowerLimit;
	private static double[][] upperLimit;
	private static int lastId = 0;
	private static boolean lastRank = false;
	private static double lastUpperMatchDistance = -1, lastPartialMatchDistance = -1;
	private static double lastUpperSignalFactor = -1, lastPartialSignalFactor = -1;
	private static List<MemoryPeakResults> resultsList = null;
	private static int candidates;
	private static double matches;
	private static double c_tn, c_fn;
	private static StoredDataStatistics depthStats, depthFitStats;

	private boolean isHeadless;
	private long totalTime = 0, currentTime;

	private static String[] COLUMNS = {
			// Scores against the fit results that did not fail		
			"nP", "TP", "FP", "TN", "FN", "TPR", "TNR", "PPV", "NPV", "FPR", "FNR", "FDR", "ACC", "MCC",
			"Informedness", "Markedness", "Recall", "Precision", "F1", "Jaccard",
			// Scores against the original localisations. Calculated using the number of localisations 
			"oFP", "oFN", "oRecall", "oPrecision", "oF1", "oJaccard", };

	private static boolean[] showColumns;
	static
	{
		showColumns = new boolean[COLUMNS.length];
		//Arrays.fill(showColumns, true);
		//showColumns[0] = false; // nP

		showColumns[1] = true; // TP
		showColumns[2] = true; // FP
		showColumns[3] = true; // TN
		showColumns[4] = true; // FN
		showColumns[COLUMNS.length - 13] = true; // MCC
		showColumns[COLUMNS.length - 10] = true; // Recall
		showColumns[COLUMNS.length - 9] = true; // Precision
		showColumns[COLUMNS.length - 7] = true; // Jaccard
		showColumns[COLUMNS.length - 6] = true; // oFP
		showColumns[COLUMNS.length - 5] = true; // oFN
		showColumns[COLUMNS.length - 4] = true; // oRecall
		showColumns[COLUMNS.length - 3] = true; // oPrecision
		showColumns[COLUMNS.length - 1] = true; // oJaccard

		// Use the precision as criteria to ensure a set confidence on results labelled as true
		criteriaIndex = COLUMNS.length - 3;
		// Score against the original data so we can compare across filters and fit solvers
		scoreIndex = COLUMNS.length - 1;
	}

	private CreateData.SimulationParameters simulationParameters;

	public BenchmarkFilterAnalysis()
	{
		isHeadless = java.awt.GraphicsEnvironment.isHeadless();
	}

	/*
	 * (non-Javadoc)
	 * 
	 * @see ij.plugin.PlugIn#run(java.lang.String)
	 */
	public void run(String arg)
	{
		simulationParameters = CreateData.simulationParameters;
		if (simulationParameters == null)
		{
			IJ.error(TITLE, "No benchmark spot parameters in memory");
			return;
		}
		if (BenchmarkSpotFit.fitResults == null)
		{
			IJ.error(TITLE, "No benchmark fitting results in memory");
			return;
		}
		if (BenchmarkSpotFit.lastId != simulationParameters.id)
		{
			IJ.error(TITLE, "Update the benchmark spot fitting for the latest simulation");
			return;
		}
		if (BenchmarkSpotFit.lastFilterId != BenchmarkSpotFilter.filterResultsId)
		{
			IJ.error(TITLE, "Update the benchmark spot fitting for the latest filter");
			return;
		}

		resultsList = readResults();
		if (resultsList.isEmpty())
		{
			IJ.error(TITLE, "No results could be loaded");
			return;
		}

		if (!showDialog(resultsList))
			return;

		// Load filters from file
		List<FilterSet> filterSets = readFilterSets();

		if (filterSets == null || filterSets.isEmpty())
		{
			IJ.error(TITLE, "No filters specified");
			return;
		}

		analyse(resultsList, filterSets);

		IJ.showStatus("Finished : " + Utils.timeToString(totalTime));
	}

	@SuppressWarnings("unchecked")
	private List<FilterSet> readFilterSets()
	{
		GlobalSettings gs = SettingsManager.loadSettings();
		FilterSettings filterSettings = gs.getFilterSettings();

		String filename = Utils.getFilename("Filter_File", filterSettings.filterSetFilename);
		if (filename != null)
		{
			IJ.showStatus("Reading filters ...");
			filterSettings.filterSetFilename = filename;

			// Allow the filters to be cached
			if (isSameFile(filename))
			{
				GenericDialog gd = new GenericDialog(TITLE);
				gd.hideCancelButton();
				gd.addMessage("The same filter file was selected.");
				gd.addCheckbox("Re-use_filters", reUseFilters);
				gd.showDialog();
				if (!gd.wasCanceled())
				{
					if ((reUseFilters = gd.getNextBoolean()))
						return filterList;
				}
			}

			BufferedReader input = null;
			setLastFile(null);
			try
			{
				FileInputStream fis = new FileInputStream(filename);
				input = new BufferedReader(new UnicodeReader(fis, null));
				Object o = XStreamWrapper.getInstance().fromXML(input);
				if (o != null && o instanceof List<?>)
				{
					SettingsManager.saveSettings(gs);
					filterList = (List<FilterSet>) o;

					// Option to enumerate filters
					expandFilters();

					// Sort so that the filters are in a nice order
					for (FilterSet filterSet : filterList)
						filterSet.sort();

					setLastFile(filename);
					return filterList;
				}
				IJ.log("No filter sets defined in the specified file: " + filename);
			}
			catch (Exception e)
			{
				IJ.log("Unable to load the filter sets from file: " + e.getMessage());
			}
			finally
			{
				if (input != null)
				{
					try
					{
						input.close();
					}
					catch (IOException e)
					{
						// Ignore
					}
				}
				IJ.showStatus("");
			}
		}
		return null;
	}

	private static boolean wasNotExpanded(int setNumber, int parameterNumber)
	{
		setNumber--;
		if (wasNotExpanded[setNumber] == null)
			return true;
		return wasNotExpanded[setNumber][parameterNumber];
	}

	/**
	 * If filters have been provided in FiltersSets of 3 then expand the filters into a set assuming the three represent
	 * min:max:increment.
	 */
	private void expandFilters()
	{
		wasNotExpanded = new boolean[filterList.size()][];
		lowerLimit = new double[filterList.size()][];
		upperLimit = new double[filterList.size()][];
		long[] expanded = new long[filterList.size()];
		String[] name = new String[expanded.length];
		int c = 0;
		boolean doIt = false;
		for (FilterSet filterSet : filterList)
		{
			if (filterSet.size() == 3 && filterSet.allSameType())
			{
				name[c] = filterSet.getName();
				// Check we have min:max:increment
				Filter f1 = filterSet.getFilters().get(0);
				Filter f2 = filterSet.getFilters().get(1);
				Filter f3 = filterSet.getFilters().get(2);
				int n = f1.getNumberOfParameters();
				wasNotExpanded[c] = new boolean[n];
				lowerLimit[c] = new double[n];
				upperLimit[c] = new double[n];
				long combinations = 1;
				for (int i = 0; i < n; i++)
				{
					wasNotExpanded[c][i] = true;
					if (f1.getParameterValue(i) < f2.getParameterValue(i) && f3.getParameterValue(i) > 0)
					{
						wasNotExpanded[c][i] = false;
						// This can be expanded ... Count the combinations
						BigDecimal min = new BigDecimal(f1.getParameterValue(i));
						BigDecimal max = new BigDecimal(f2.getParameterValue(i));
						BigDecimal inc = new BigDecimal(f3.getParameterValue(i));
						lowerLimit[c][i] = min.doubleValue();
						long extra = 1;
						for (BigDecimal bd = min.add(inc); bd.compareTo(max) <= 0; bd = bd.add(inc))
						{
							upperLimit[c][i] = bd.doubleValue();
							extra++;
						}
						combinations *= extra;
					}
				}
				if (combinations > 1)
				{
					expanded[c] = combinations;
					doIt = true;
				}
			}
			c++;
		}

		if (!doIt)
			return;

		GenericDialog gd = new GenericDialog(TITLE);
		gd.hideCancelButton();
		StringBuilder sb = new StringBuilder("The filter file contains potential triples of min:max:increment.\n \n");
		for (c = 0; c < expanded.length; c++)
		{
			if (expanded[c] > 0)
			{
				sb.append("Expand set [").append((c + 1)).append("]");
				if (!Utils.isNullOrEmpty(name[c]))
					sb.append(" ").append(name[c]);
				sb.append(" to ").append(expanded[c]).append(" filters\n");
			}
		}
		gd.addMessage(sb.toString());
		gd.addCheckbox("Expand_filters", expandFilters);
		gd.showDialog();
		if (!gd.wasCanceled())
		{
			if (!(expandFilters = gd.getNextBoolean()))
				return;
		}

		IJ.showStatus("Expanding filters ...");

		List<FilterSet> filterList2 = new LinkedList<FilterSet>();
		c = 0;
		for (FilterSet filterSet : filterList)
		{
			if (expanded[c] == 0)
			{
				filterList2.add(filterSet);
				continue;
			}

			List<Filter> list = new LinkedList<Filter>();

			Filter f1 = filterSet.getFilters().get(0);
			Filter f2 = filterSet.getFilters().get(1);
			Filter f3 = filterSet.getFilters().get(2);
			final int n = f1.getNumberOfParameters();

			// Initialise with a filter set at the minimum for each parameter
			list.add(f1);
			for (int i = 0; i < n; i++)
			{
				// Use Big Decimal for the enumeration to preserve the precision of the input text
				// (i.e. using doubles for an enumeration can lose precision and fail to correctly enumerate)
				BigDecimal min = new BigDecimal(f1.getParameterValue(i));
				BigDecimal max = new BigDecimal(f2.getParameterValue(i));
				BigDecimal inc = new BigDecimal(f3.getParameterValue(i));

				if (!(f1.getParameterValue(i) < f2.getParameterValue(i) && f3.getParameterValue(i) > 0))
				{
					// No expansion of this parameter
					continue;
				}

				List<Filter> list2 = new LinkedList<Filter>();
				for (Filter f : list)
				{
					double[] parameters = new double[n];
					for (int j = 0; j < n; j++)
						parameters[j] = f.getParameterValue(j);

					// We always have the min value set from the first filter so start at the next increment
					for (BigDecimal bd = min.add(inc); bd.compareTo(max) <= 0; bd = bd.add(inc))
					{
						parameters[i] = bd.doubleValue();
						list2.add(f.create(parameters));
					}
				}
				list.addAll(list2);
			}

			// Sort the filters
			Collections.sort(list);

			filterList2.add(new FilterSet(filterSet.getName(), list));
		}

		IJ.showStatus("");

		filterList = filterList2;
		Utils.log("Expanded input to %d filters in %s", countFilters(filterList),
				Utils.pleural(filterList.size(), "set"));
	}

	public boolean isSameFile(String filename)
	{
		if (filterList == null)
			return false;
		if (filename.equals(oldFilename))
		{
			try
			{
				File f = new File(filename);
				if (lastModified == f.lastModified())
				{
					return true;
				}
			}
			catch (Exception e)
			{
			}
		}
		return false;
	}

	private void setLastFile(String filename)
	{
		oldFilename = filename;
		if (oldFilename != null)
		{
			try
			{
				File f = new File(filename);
				lastModified = f.lastModified();
			}
			catch (Exception e)
			{
				lastModified = 0;
			}
		}
	}

	private List<MemoryPeakResults> readResults()
	{
		if (resultsList == null || lastId != BenchmarkSpotFit.fitResultsId || lastRank != rerankBySignal ||
				lastPartialMatchDistance != partialMatchDistance || lastUpperMatchDistance != upperMatchDistance ||
				lastPartialSignalFactor != partialSignalFactor || lastUpperSignalFactor != upperSignalFactor)
		{
			lastId = BenchmarkSpotFit.fitResultsId;
			lastRank = rerankBySignal;
			lastUpperMatchDistance = upperMatchDistance;
			lastPartialMatchDistance = partialMatchDistance;
			lastUpperSignalFactor = upperSignalFactor;
			lastPartialSignalFactor = partialSignalFactor;
			resultsList = new LinkedList<MemoryPeakResults>();
			depthStats = new StoredDataStatistics();
			depthFitStats = new StoredDataStatistics();
			candidates = 0;
			matches = 0;
			c_tn = c_fn = 0;

			// -=-=-=-
			// The scoring is designed to find the best fitter+filter combination for the given spot candidates.
			// The ideal combination would correctly fit+pick all the candidate positions that are close to a
			// localisation.
			//
			// Use the following scoring scheme for all candidates:
			// 
			//  Candidates
			// +----------------------------------------+  
			// |   Actual matches                       | 
			// |  +-----------+                TN       |
			// |  |  FN       |                         |
			// |  |      +----------                    |
			// |  |      | TP |    | Fitted             |
			// |  +-----------+    | spots              |
			// |         |     FP  |                    |
			// |         +---------+                    |
			// +----------------------------------------+
			//
			// Candidates     = All the spot candidates
			// Actual matches = Any spot candidate or fitted spot candidate that matches a localisation
			// Fitted spots   = Any spot candidate that was successfully fitted
			//
			// TP = A spot candidate that was fitted and matches a localisation and is accepted
			// FP = A spot candidate that was fitted but does not match a localisation and is accepted
			// FN = A spot candidate that failed to be fitted but matches a localisation
			//    = A spot candidate that was fitted and matches a localisation and is rejected
			// TN = A spot candidate that failed to be fitted and does not match a localisation
			//    = A spot candidate that was fitted and does not match a localisation and is rejected
			//
			// Since unfitted candidates can only be TN or FN we can accumulate these scores and cache them.
			//
			// Using a distance ramped scoring function the degree of match can be varied from 0 to 1.
			// Using a signal-factor ramped scoring function the degree of fitted can be varied from 0 to 1.
			// When using ramped scoring functions the fractional allocation of scores using the above scheme 
			// is performed, i.e. candidates are treated as if they both match and unmatch. This results in 
			// an equivalent to multiple analysis using different thresholds and averaging of the scores.
			//
			// The totals TP+FP+TN+FN must equal the number of spot candidates. This allows different fitting 
			// methods to be compared since the total number of candidates is the same.
			//
			// Precision = TP / (TP+FP)    : This is always valid as a minimum criteria score
			// Recall    = TP / (TP+FN)    : This is valid between different fitting methods since a method that 
			//                               fits more spots will have a potentially lower FN
			// Jaccard   = TP / (TP+FN+FP) : This is valid between fitting methods
			//
			// -=-=-=-
			// As an alternative scoring system, different fitting methods can be compared using the same TP 
			// value but calculating FN = localisations - TP and FP as Positives - TP. This creates a score 
			// against the original number of simulated molecules using everything that was passed through the 
			// filter (Positives). This score is comparable when a different spot candidate filter has been used 
			// and the total number of candidates is different, e.g. Mean filtering vs. Gaussian filtering
			// -=-=-=-

			final RampedScore distanceScore = new RampedScore(BenchmarkSpotFit.distanceInPixels * partialMatchDistance /
					100.0, BenchmarkSpotFit.distanceInPixels * upperMatchDistance / 100.0);

			resultsPrefix3 = "\t" + Utils.rounded(distanceScore.lower * simulationParameters.a) + "\t" +
					Utils.rounded(distanceScore.upper * simulationParameters.a);

			// Signal factor must be greater than 1
			final RampedScore signalScore;
			if (BenchmarkSpotFit.signalFactor > 1)
			{
				signalScore = new RampedScore(BenchmarkSpotFit.signalFactor * upperSignalFactor / 100.0,
						BenchmarkSpotFit.signalFactor * partialSignalFactor / 100.0);
				resultsPrefix3 += "\t" + Utils.rounded(signalScore.lower) + "\t" + Utils.rounded(signalScore.upper);
			}
			else
			{
				signalScore = null;
				resultsPrefix3 += "\t0\t0";
			}

			MemoryPeakResults r = new MemoryPeakResults();
			Calibration cal = new Calibration(simulationParameters.a, simulationParameters.gain, 100);
			cal.bias = simulationParameters.bias;
			cal.emCCD = simulationParameters.emCCD;
			cal.readNoise = simulationParameters.readNoise;
			r.setCalibration(cal);
			// Set the configuration used for fitting
			r.setConfiguration(XmlUtils.toXML(BenchmarkSpotFit.fitConfig));

			for (Entry<Integer, FilterCandidates> entry : BenchmarkSpotFit.fitResults.entrySet())
			{
				final int peak = entry.getKey().intValue();
				final FilterCandidates result = entry.getValue();
				depthStats.add(result.zPosition);
				candidates += result.spots.length;

				// Results are in order of candidate ranking.
				int[] indices = Utils.newArray(result.fitResult.length, 0, 1);
				if (rerankBySignal)
				{
					// Change to signal intensity.
					double[] score = new double[result.fitResult.length];
					for (int i = 0; i < result.fitResult.length; i++)
					{
						final FitResult fitResult = result.fitResult[i];
						if (fitResult.getStatus() == FitStatus.OK)
						{
							score[i] = fitResult.getParameters()[Gaussian2DFunction.SIGNAL];
						}
					}
					Sort.sort(indices, score);
				}

				for (int i = 0; i < result.fitResult.length; i++)
				{
					final int index = indices[i];
					final FitResult fitResult = result.fitResult[index];
					if (fitResult.getStatus() == FitStatus.OK)
					{
						// Assume we are not fitting doublets and the fit result will have 1 peak
						final float[] params = Utils.toFloat(fitResult.getParameters());
						// To allow the shift filter to function the X/Y position coordinates must be relative
						final double[] initial = fitResult.getInitialParameters();
						params[Gaussian2DFunction.X_POSITION] -= initial[Gaussian2DFunction.X_POSITION];
						params[Gaussian2DFunction.Y_POSITION] -= initial[Gaussian2DFunction.Y_POSITION];
						// These will be incorrect due to the relative adjustment above...
						final int origX = (int) params[Gaussian2DFunction.X_POSITION];
						final int origY = (int) params[Gaussian2DFunction.Y_POSITION];

						// Binary classification uses a score of 1 (match) or 0 (no match)
						// Fuzzy classification uses a score of 1 (match) or 0 (no match), or >0 <1 (partial match)
						double matchScore = 0, noMatchScore = 1;
						double depth = 0;
						if (result.fitMatch[index])
						{
							// Find the result
							SpotMatch match = getMatch(result.match, index);

							// Store depth of matches for later analysis
							depth = match.z;

							final double dScore = distanceScore.scoreAndFlatten(match.d, 256);
							if (dScore > 0)
								matches += dScore;
							matchScore = dScore;
							noMatchScore = 1 - matchScore;

							// Apply the weighting for the signal factor if enabled
							if (signalScore != null)
							{
								final double fScore = signalScore.scoreAndFlatten(match.getSignalFactor(), 256);
								matchScore = RampedScore.flatten(matchScore * fScore, 256);
								noMatchScore = fScore - matchScore;

								// Any remaining score should be accumulated as an unfitted result,
								// i.e. since the signal fit is poor then treat this as partially unfitted.

								// Allocate the removed match score to false-negative
								final double fn = dScore - matchScore;
								// The remaining score is true negative, ensure it sums to 1
								final double tn = 1 - matchScore - noMatchScore - fn;
								c_fn += fn;
								c_tn += tn;
							}

							if (matchScore > 0)
							{
								depthFitStats.add(depth);
							}
						}

						final float score2 = RampedScore.flatten((float) matchScore, 256);

						// Use a custom peak result so that the depth can be stored.
						r.add(new DepthPeakResult(peak, origX, origY, score2, fitResult.getError(), result.noise,
								params, depth, matchScore, noMatchScore));
					}
					else
					{
						// This was not fitted
						c_tn++;
					}
				}

				// Accumulate the TN and FN scores for spot candidates that were not fitted but match a result
				for (SpotMatch match : result.match)
				{
					if (match.isFitResult())
						// This has been processed above as a fitMatch
						continue;
					// This is an unfitted result that matches so is a negative
					final double dScore = distanceScore.scoreAndFlatten(match.d, 256);
					matches += dScore;
					c_fn += dScore;
					// This should be '+= 1 - dScore' but we incremented c_tn above for all candidates that were not fitted
					c_tn -= dScore;
				}
			}

			checkTotals(r, c_tn, c_fn);

			if (r.size() > 0)
			{
				resultsList.add(r);
			}
		}
		return resultsList;
	}

	/**
	 * Check the current scoring totals sum to the number of spot candidates
	 * 
	 * @param r
	 * @param tn
	 * @param fn
	 */
	private void checkTotals(MemoryPeakResults r, double tn, double fn)
	{
		double tp = 0, fp = 0;
		for (PeakResult peak : r.getResults())
		{
			tp += peak.getTruePositiveScore();
			fp += peak.getFalsePositiveScore();
		}
		checkTotals(tp, fp, tn, fn);
	}

	/**
	 * Check the scoring totals sum to the number of spot candidates
	 * 
	 * @param tp
	 * @param fp
	 * @param tn
	 * @param fn
	 */
	private void checkTotals(double tp, double fp, double tn, double fn)
	{
		final double t = tp + fp + tn + fn;
		final double t2 = tp + fn;
		if (candidates != t || t2 != matches)
		{
			System.out.printf("Scoring error: n = %d (%f), matches = %f (%f), TP %f, FP %f, TN %f, FN %f\n",
					candidates, t, matches, t2, tp, fp, tn, fn);
		}
	}

	private SpotMatch getMatch(SpotMatch[] match, int index)
	{
		for (SpotMatch m : match)
			if (m.i == index)
				return m;
		throw new RuntimeException("Cannot find the match for the position");
	}

	private boolean showDialog(List<MemoryPeakResults> resultsList)
	{
		GenericDialog gd = new GenericDialog(TITLE);
		gd.addHelp(About.HELP_URL);

		int total = 0;
		int tp = 0;
		for (MemoryPeakResults r : resultsList)
		{
			total += r.size();
			for (PeakResult p : r.getResults())
				if (p.origValue != 0)
					tp++;
		}
		gd.addMessage(String.format("%d results, %d True-Positives", total, tp));

		gd.addSlider("Fail_count", 0, 20, failCount);
		gd.addSlider("Fail_count_range", 0, 5, failCountRange);
		gd.addCheckbox("Rank_by_signal", rerankBySignal);
		gd.addCheckbox("Show_table", showResultsTable);
		gd.addCheckbox("Show_summary", showSummaryTable);
		gd.addCheckbox("Clear_tables", clearTables);
		gd.addSlider("Summary_top_n", 0, 20, summaryTopN);
		gd.addNumericField("Summary_depth (nm)", summaryDepth, 0);
		gd.addSlider("Plot_top_n", 0, 20, plotTopN);
		gd.addCheckbox("Save_best_filter", saveBestFilter);
		gd.addCheckbox("Calculate_sensitivity", calculateSensitivity);
		gd.addSlider("Delta", 0.01, 1, delta);
		gd.addChoice("Criteria", COLUMNS, COLUMNS[criteriaIndex]);
		gd.addNumericField("Criteria_limit", criteriaLimit, 4);
		gd.addChoice("Score", COLUMNS, COLUMNS[scoreIndex]);
		gd.addMessage(String.format("Fitting match distance = %s nm; signal factor = %s",
				Utils.rounded(BenchmarkSpotFit.distanceInPixels * simulationParameters.a),
				Utils.rounded(BenchmarkSpotFit.signalFactor)));
		gd.addSlider("Upper_match_distance (%)", 0, 100, upperMatchDistance);
		gd.addSlider("Partial_match_distance (%)", 0, 100, partialMatchDistance);
		gd.addSlider("Upper_signal_factor (%)", 0, 100, upperSignalFactor);
		gd.addSlider("Partial_signal_factor (%)", 0, 100, partialSignalFactor);
		if (!simulationParameters.fixedDepth)
			gd.addCheckbox("Depth_recall_analysis", depthRecallAnalysis);
		gd.addCheckbox("Evolve", evolve);
		gd.addStringField("Title", resultsTitle, 20);

		gd.showDialog();

		if (gd.wasCanceled() || !readDialog(gd))
			return false;

		if (showResultsTable || showSummaryTable)
		{
			gd = new GenericDialog(TITLE);
			gd.addHelp(About.HELP_URL);

			gd.addMessage("Select the results:");
			for (int i = 0; i < COLUMNS.length; i++)
				gd.addCheckbox(COLUMNS[i], showColumns[i]);
			gd.showDialog();

			if (gd.wasCanceled())
				return false;

			for (int i = 0; i < COLUMNS.length; i++)
				showColumns[i] = gd.getNextBoolean();
		}

		// We may have to read the results again if the ranking option has changed
		if (lastRank != rerankBySignal || lastPartialMatchDistance != partialMatchDistance ||
				lastUpperMatchDistance != upperMatchDistance || lastPartialSignalFactor != partialSignalFactor ||
				lastUpperSignalFactor != upperSignalFactor)
			readResults();

		return true;
	}

	private boolean readDialog(GenericDialog gd)
	{
		failCount = (int) Math.abs(gd.getNextNumber());
		failCountRange = (int) Math.abs(gd.getNextNumber());
		rerankBySignal = gd.getNextBoolean();
		showResultsTable = gd.getNextBoolean();
		showSummaryTable = gd.getNextBoolean();
		clearTables = gd.getNextBoolean();
		summaryTopN = (int) Math.abs(gd.getNextNumber());
		summaryDepth = Math.abs(gd.getNextNumber());
		plotTopN = (int) Math.abs(gd.getNextNumber());
		saveBestFilter = gd.getNextBoolean();
		calculateSensitivity = gd.getNextBoolean();
		delta = gd.getNextNumber();
		criteriaIndex = gd.getNextChoiceIndex();
		criteriaLimit = gd.getNextNumber();
		scoreIndex = gd.getNextChoiceIndex();
		upperMatchDistance = Math.abs(gd.getNextNumber());
		partialMatchDistance = Math.abs(gd.getNextNumber());
		upperSignalFactor = Math.abs(gd.getNextNumber());
		partialSignalFactor = Math.abs(gd.getNextNumber());
		if (!simulationParameters.fixedDepth)
			depthRecallAnalysis = gd.getNextBoolean();
		evolve = gd.getNextBoolean();
		resultsTitle = gd.getNextString();

		resultsPrefix = BenchmarkSpotFit.resultPrefix + "\t" + resultsTitle + "\t";
		resultsPrefix2 = "\t" + failCount;
		if (failCountRange > 0)
			resultsPrefix2 += "-" + (failCount + failCountRange);

		// Check there is one output
		if (!showResultsTable && !showSummaryTable && !calculateSensitivity && plotTopN < 1 && !saveBestFilter)
		{
			IJ.error(TITLE, "No output selected");
			return false;
		}

		// Check arguments
		try
		{
			Parameters.isAboveZero("Delta", delta);
			Parameters.isBelow("Delta", delta, 1);
			Parameters.isEqualOrBelow("Partial match distance", partialMatchDistance, upperMatchDistance);
			Parameters.isEqualOrBelow("Partial signal factor", partialSignalFactor, upperSignalFactor);
		}
		catch (IllegalArgumentException e)
		{
			IJ.error(TITLE, e.getMessage());
			return false;
		}

		invertCriteria = requiresInversion(criteriaIndex);
		minCriteria = (invertCriteria) ? -criteriaLimit : criteriaLimit;
		invertScore = requiresInversion(scoreIndex);

		return !gd.invalidNumber();
	}

	/**
	 * Run different filtering methods on a set of labelled peak results outputting performance statistics on the
	 * success of
	 * the filter to an ImageJ table.
	 * <p>
	 * If the peak result original value is set to 1 it is considered a true peak, 0 for a false peak. Filtering is done
	 * using e.g. SNR threshold, Precision thresholds, etc. The statistics reported are shown in a table, e.g.
	 * precision, Jaccard, F-score.
	 * <p>
	 * For each filter set a plot is shown of the score verses the filter value, thus filters should be provided in
	 * ascending numerical order otherwise they are sorted.
	 * 
	 * @param resultsList
	 * @param filterSets
	 */
	private void analyse(List<MemoryPeakResults> resultsList, List<FilterSet> filterSets)
	{
		createResultsWindow();
		plots = new ArrayList<NamedPlot>(plotTopN);
		bestFilter = new HashMap<String, FilterScore>();
		bestFilterOrder = new LinkedList<String>();

		startTimer();
		IJ.showStatus("Analysing filters ...");
		int total = countFilters(filterSets);
		int count = 0;
		int setNumber = 0;
		for (FilterSet filterSet : filterSets)
		{
			setNumber++;
			if (run(filterSet, setNumber, resultsList, count, total) < 0)
				break;
			count += filterSet.size();
		}
		stopTimer();
		IJ.showProgress(1);
		IJ.showStatus("");

		if (Utils.isInterrupted())
			return;

		if (bestFilter.isEmpty())
		{
			IJ.log("Warning: No filters pass the criteria");
			return;
		}

		List<FilterScore> filters = new ArrayList<FilterScore>(bestFilter.values());
		if (showSummaryTable || saveBestFilter)
			Collections.sort(filters);

		if (showSummaryTable)
		{
			createSummaryWindow();
			int n = 0;
			final double range = summaryDepth / simulationParameters.a / 2;
			int np = 0;
			for (double depth : depthStats.getValues())
			{
				if (Math.abs(depth) < range)
					np++;
			}
			for (FilterScore fs : filters)
			{
				FractionClassificationResult r = scoreFilter(fs.filter, resultsList);
				String text = createResult(fs.filter, r);

				// Show the recall at the specified depth
				MemoryPeakResults results = fs.filter.filter(resultsList.get(0), failCount);
				int tp = 0;
				for (PeakResult result : results.getResults())
				{
					if (result.origValue != 0 && Math.abs(((DepthPeakResult) result).depth) <= range)
						tp++;
				}

				text += "\t" + Utils.rounded((double) tp / np);
				if (fs.atLimit)
					text += "\tY";

				if (isHeadless)
					IJ.log(text);
				else
					summaryWindow.append(text);
				n++;
				if (summaryTopN > 0 && n >= summaryTopN)
					break;
			}
			// Add a spacer to the summary table if we have multiple results
			if (n > 1)
			{
				if (isHeadless)
					IJ.log("");
				else
					summaryWindow.append("");
			}
		}

		if (saveBestFilter)
			saveFilter(filters.get(0).filter);

		showPlots();
		calculateSensitivity(resultsList);
		depthAnalysis(filters.get(0).filter);
	}

	private void startTimer()
	{
		currentTime = System.currentTimeMillis();
	}

	private void stopTimer()
	{
		totalTime += System.currentTimeMillis() - currentTime;
	}

	private int countFilters(List<FilterSet> filterSets)
	{
		int count = 0;
		for (FilterSet filterSet : filterSets)
			count += filterSet.size();
		return count;
	}

	private void showPlots()
	{
		if (plots.isEmpty())
			return;

		// Display the top N plots
		int[] list = new int[plots.size()];
		int i = 0;
		for (NamedPlot p : plots)
		{
			Plot2 plot = new Plot2(p.name, p.xAxisName, COLUMNS[scoreIndex], p.xValues, p.yValues);
			plot.setLimits(p.xValues[0], p.xValues[p.xValues.length - 1], 0, 1);
			plot.setColor(Color.RED);
			plot.draw();
			plot.setColor(Color.BLUE);
			plot.addPoints(p.xValues, p.yValues, Plot2.CROSS);
			PlotWindow plotWindow = Utils.display(p.name, plot);
			list[i++] = plotWindow.getImagePlus().getID();
		}
		new WindowOrganiser().tileWindows(list);
	}

	private void calculateSensitivity(List<MemoryPeakResults> resultsList)
	{
		if (!calculateSensitivity)
			return;
		if (!bestFilter.isEmpty())
		{
			IJ.showStatus("Calculating sensitivity ...");
			createSensitivityWindow();

			int currentIndex = 0;
			for (String type : bestFilterOrder)
			{
				IJ.showProgress(currentIndex++, bestFilter.size());

				Filter filter = bestFilter.get(type).filter;

				FractionClassificationResult s = scoreFilter(filter, resultsList);

				String message = type + "\t\t\t" + Utils.rounded(s.getJaccard(), 4) + "\t\t" +
						Utils.rounded(s.getPrecision(), 4) + "\t\t" + Utils.rounded(s.getRecall(), 4);

				if (isHeadless)
				{
					IJ.log(message);
				}
				else
				{
					sensitivityWindow.append(message);
				}

				// List all the parameters that can be adjusted.
				final int parameters = filter.getNumberOfParameters();
				for (int index = 0; index < parameters; index++)
				{
					// For each parameter compute as upward + downward delta and get the average gradient
					Filter higher = filter.adjustParameter(index, delta);
					Filter lower = filter.adjustParameter(index, -delta);

					FractionClassificationResult sHigher = scoreFilter(higher, resultsList);
					FractionClassificationResult sLower = scoreFilter(lower, resultsList);

					StringBuilder sb = new StringBuilder();
					sb.append("\t").append(filter.getParameterName(index)).append("\t");
					sb.append(Utils.rounded(filter.getParameterValue(index), 4)).append("\t");

					double dx1 = higher.getParameterValue(index) - filter.getParameterValue(index);
					double dx2 = filter.getParameterValue(index) - lower.getParameterValue(index);
					addSensitivityScore(sb, s.getJaccard(), sHigher.getJaccard(), sLower.getJaccard(), dx1, dx2);
					addSensitivityScore(sb, s.getPrecision(), sHigher.getPrecision(), sLower.getPrecision(), dx1, dx2);
					addSensitivityScore(sb, s.getRecall(), sHigher.getRecall(), sLower.getRecall(), dx1, dx2);

					if (isHeadless)
					{
						IJ.log(sb.toString());
					}
					else
					{
						sensitivityWindow.append(sb.toString());
					}
				}
			}

			String message = "-=-=-=-";
			if (isHeadless)
			{
				IJ.log(message);
			}
			else
			{
				sensitivityWindow.append(message);
			}

			IJ.showProgress(1);
			IJ.showStatus("");
		}
	}

	private void addSensitivityScore(StringBuilder sb, double s, double s1, double s2, double dx1, double dx2)
	{
		// Use absolute in case this is not a local maximum. We are mainly interested in how
		// flat the curve is at this point in relation to parameter changes.
		double abs = 0, dydx = 0;
		int count = 0;
		if (dx1 > 0)
		{
			double abs1 = Math.abs(s - s1);
			double dydx1 = abs1 / dx1;
			abs += abs1;
			dydx += dydx1;
			count++;
		}
		if (dx2 > 0)
		{
			double abs2 = Math.abs(s - s2);
			double dydx2 = abs2 / dx2;
			abs += abs2;
			dydx += dydx2;
			count++;
		}

		double relativeSensitivity = 0, sensitivity = 0;
		if (count != 0)
		{
			relativeSensitivity = abs / count;
			sensitivity = dydx / count;
		}

		sb.append(Utils.rounded(relativeSensitivity, 4)).append("\t");
		sb.append(Utils.rounded(sensitivity, 4)).append("\t");
	}

	private void createResultsWindow()
	{
		if (!showResultsTable)
			return;

		if (isHeadless)
		{
			IJ.log(createResultsHeader(false));
		}
		else
		{
			if (resultsWindow == null || !resultsWindow.isShowing())
			{
				String header = createResultsHeader(false);
				resultsWindow = new TextWindow(TITLE + " Results", header, "", 900, 300);
			}
			if (clearTables)
				resultsWindow.getTextPanel().clear();
		}
	}

	private void createSummaryWindow()
	{
		if (!showSummaryTable)
			return;

		if (isHeadless)
		{
			IJ.log(createResultsHeader(true));
		}
		else
		{
			if (summaryWindow == null || !summaryWindow.isShowing())
			{
				String header = createResultsHeader(true);
				summaryWindow = new TextWindow(TITLE + " Summary", header, "", 900, 300);
			}
			if (clearTables)
				summaryWindow.getTextPanel().clear();
		}
	}

	private void createGAWindow()
	{
		if (isHeadless)
		{
			String header = createResultsHeader(false);
			header += "\tIteration";
			IJ.log(header);
		}
		else
		{
			if (gaWindow == null || !gaWindow.isShowing())
			{
				String header = createResultsHeader(false);
				header += "\tIteration";
				gaWindow = new TextWindow(TITLE + " Evolution", header, "", 900, 300);
			}
			if (clearTables)
				gaWindow.getTextPanel().clear();
		}
	}

	private String createResultsHeader(boolean summary)
	{
		StringBuilder sb = new StringBuilder(BenchmarkSpotFit.tablePrefix);
		sb.append("\tTitle\tName\tFail\tLower D (nm)\tUpper D (nm)\tLower factor\tUpper factor");

		for (int i = 0; i < COLUMNS.length; i++)
			if (showColumns[i])
				sb.append("\t").append(COLUMNS[i]);

		if (summary)
			sb.append("\tDepth Recall\tAt limit");
		return sb.toString();
	}

	private void createSensitivityWindow()
	{
		if (isHeadless)
		{
			IJ.log(createSensitivityHeader());
		}
		else
		{
			if (sensitivityWindow == null || !sensitivityWindow.isShowing())
			{
				String header = createSensitivityHeader();
				sensitivityWindow = new TextWindow(TITLE + " Sensitivity", header, "", 900, 300);
			}
		}
	}

	private String createSensitivityHeader()
	{
		StringBuilder sb = new StringBuilder();
		sb.append("Filter\t");
		sb.append("Param\t");
		sb.append("Value\t");
		sb.append("J Sensitivity (delta)\t");
		sb.append("J Sensitivity (unit)\t");
		sb.append("P Sensitivity (delta)\t");
		sb.append("P Sensitivity (unit)\t");
		sb.append("R Sensitivity (delta)\t");
		sb.append("R Sensitivity (unit)\t");
		return sb.toString();
	}

	private int run(FilterSet filterSet, int setNumber, List<MemoryPeakResults> resultsList, final int count,
			final int total)
	{
		int originalSize = filterSet.size();

		// Get the weakest filter and subset the results if possible
		final boolean allSameType = filterSet.allSameType();

		this.ga_resultsList = resultsList;
		Chromosome best = null;

		if (evolve && allSameType)
		{
			// Collect parameters for the genetic algorithm
			stopTimer();

			createGAWindow();

			Filter filter = filterSet.getFilters().get(0);
			double[] stepSize = filter.mutationStepRange().clone();
			double[] upper = filter.upperLimit().clone();
			// Ask the user for the mutation step parameters.
			GenericDialog gd = new GenericDialog(TITLE);
			String prefix = setNumber + "_";
			gd.addMessage("Configure the genetic algorithm for [" + setNumber + "] " + filterSet.getName());
			gd.addNumericField(prefix + "Population_size", populationSize, 0);
			gd.addNumericField(prefix + "Failure_limit", failureLimit, 0);
			gd.addNumericField(prefix + "Tolerance", tolerance, -1);
			gd.addNumericField(prefix + "Converged_count", convergedCount, 0);
			gd.addSlider(prefix + "Mutation_rate", 0.05, 1, mutationRate);
			gd.addSlider(prefix + "Crossover_rate", 0.05, 1, crossoverRate);
			gd.addSlider(prefix + "Mean_children", 0.05, 3, meanChildren);
			gd.addSlider(prefix + "Selection_fraction", 0.05, 0.5, selectionFraction);
			gd.addCheckbox(prefix + "Ramped_selection", rampedSelection);
			gd.addCheckbox(prefix + "Strict_fitness", strictFitness);
			gd.addCheckbox(prefix + "Save_option", saveOption);

			gd.addMessage("Configure the step size for each parameter");
			int[] indices = filter.getChromosomeParameters();
			for (int j = 0; j < indices.length; j++)
			{
				// Do not mutate parameters that were not expanded, i.e. the input did not vary them.
				final double step = (wasNotExpanded(setNumber, indices[j])) ? 0 : stepSize[j] * delta;
				gd.addNumericField(getDialogName(prefix, filter.getParameterName(indices[j])), step, 2);
			}

			gd.showDialog();

			startTimer();

			if (!gd.wasCanceled())
			{
				populationSize = (int) Math.abs(gd.getNextNumber());
				if (populationSize < 10)
					populationSize = 10;
				failureLimit = (int) Math.abs(gd.getNextNumber());
				tolerance = Math.abs(gd.getNextNumber());
				convergedCount = (int) gd.getNextNumber(); // Allow negatives
				mutationRate = Math.abs(gd.getNextNumber());
				crossoverRate = Math.abs(gd.getNextNumber());
				meanChildren = Math.abs(gd.getNextNumber());
				selectionFraction = Math.abs(gd.getNextNumber());
				rampedSelection = gd.getNextBoolean();
				strictFitness = gd.getNextBoolean();
				saveOption = gd.getNextBoolean();

				for (int j = 0; j < indices.length; j++)
					stepSize[j] = Math.abs(gd.getNextNumber());

				// Create the genetic algorithm
				RandomDataGenerator random = new RandomDataGenerator(new Well44497b());
				SimpleMutator mutator = new SimpleMutator(random, mutationRate);
				// Override the settings with the step length, a min of zero and the configured upper
				mutator.overrideChromosomeSettings(stepSize, new double[stepSize.length], upper);
				Recombiner recombiner = new SimpleRecombiner(random, crossoverRate, meanChildren);
				SelectionStrategy selectionStrategy;
				if (rampedSelection)
					selectionStrategy = new RampedSelectionStrategy(random, selectionFraction);
				else
					selectionStrategy = new SimpleSelectionStrategy(random, selectionFraction);
				ToleranceChecker ga_checker = new InterruptChecker(tolerance, tolerance * 1e-3, convergedCount);
				ga_population = new Population(filterSet.getFilters());
				ga_population.setPopulationSize(populationSize);
				ga_population.setFailureLimit(failureLimit);
				selectionStrategy.setTracker(this);

				// Evolve
				ga_statusPrefix = "Evolving [" + setNumber + "] " + filterSet.getName() + " ... ";
				ga_iteration = 0;
				ga_population.setTracker(this);
				best = ga_population.evolve(mutator, recombiner, this, selectionStrategy, ga_checker);

				if (best != null)
				{
					// Now update the filter set for final assessment
					filterSet = new FilterSet(filterSet.getName(), populationToFilters(ga_population.getIndividuals()));

					// Option to save the filters
					if (saveOption)
						saveFilterSet(filterSet, setNumber);
				}
			}
		}

		IJ.showStatus("Analysing [" + setNumber + "] " + filterSet.getName() + " ...");

		double[] xValues = (isHeadless || (plotTopN == 0)) ? null : new double[filterSet.size()];
		double[] yValues = (xValues == null) ? null : new double[xValues.length];
		Filter maxFilter = null, criteriaFilter = null;
		double maxScore = -1;
		double maxCriteria = 0;

		// Final evaluation does not need to assess all the filters if we have run the GA.
		// It can just assess the top 1 required for the summary.
		if (best != null && !showResultsTable && xValues == null)
		{
			// Only assess the top 1 filter for the summary
			List<Filter> list = new ArrayList<Filter>();
			list.add((Filter) best);
			filterSet = new FilterSet(filterSet.getName(), list);
		}

		initialiseScoring(filterSet);

		// Score the filters and report the results if configured.
		// Note that count and total may have changed after running the genetic algorithm
		// so use fractional progress.
		double totalProgress = (double) count / total;
		double stepSize = ((double) originalSize / total) / filterSet.size();
		int i = 0;
		for (Filter filter : filterSet.getFilters())
		{
			if (i % 16 == 0)
			{
				IJ.showProgress(totalProgress + i * stepSize);
				if (Utils.isInterrupted())
					return -1;
			}

			final double[] result = run(filter, ga_resultsListToScore, ga_subset, ga_tn, ga_fn, ga_n);
			final double score = result[0];
			final double criteria = result[1];

			// Check if the criteria are achieved
			if (criteria >= minCriteria)
			{
				// Check if the score is better
				if (filter == null || maxScore < score)
				{
					maxScore = score;
					maxFilter = filter;
				}
			}
			else if (maxCriteria < criteria)
			{
				maxCriteria = criteria;
				criteriaFilter = filter;
			}

			if (xValues != null)
			{
				xValues[i] = filter.getNumericalValue();
				yValues[i] = score;
			}
			i++;
		}

		// Check the top filter against the limits
		boolean atLimit = false;
		if (allSameType)
		{
			Filter topFilter = (maxFilter == null) ? criteriaFilter : maxFilter;
			int[] indices = topFilter.getChromosomeParameters();
			StringBuilder sb = new StringBuilder();
			for (int j = 0; j < indices.length; j++)
			{
				final int set = setNumber - 1;
				final int p = indices[j];
				if (!wasNotExpanded(setNumber, p))
				{
					final double value = topFilter.getParameterValue(p);
					if (value <= lowerLimit[set][p] && value > 0)
						sb.append(" : ").append(topFilter.getParameterName(p)).append(" [")
								.append(Utils.rounded(value)).append("] lower");
					else if (value >= upperLimit[set][p])
						sb.append(" : ").append(topFilter.getParameterName(p)).append(" [")
								.append(Utils.rounded(value)).append("] upper");
				}
			}
			if (sb.length() > 0)
			{
				atLimit = true;
				Utils.log("Warning: Top filter (%s) at the limit of the expanded range%s", topFilter.getName(),
						sb.toString());
			}
		}

		// We may have no filters that pass the criteria
		String type = filterSet.getFilters().get(0).getType();
		if (maxFilter == null)
		{
			if (allSameType)
			{
				if (criteriaFilter != null)
					Utils.log("Warning: Filter does not pass the criteria: %s : Best = %s using %s", type,
							Utils.rounded((invertCriteria) ? -maxCriteria : maxCriteria), criteriaFilter.getName());
				else
					Utils.log("Warning: Filter does not pass the criteria: %s", type);
			}
			return 0;
		}

		boolean allowDuplicates = true; // This could be an option?

		if (allSameType)
		{
			if (bestFilter.containsKey(type))
			{
				if (allowDuplicates)
				{
					// Duplicate type: create a unique key
					// Start at 2 to show it is the second one of the same type
					int n = 2;
					while (bestFilter.containsKey(type + n))
						n++;
					type += n;
					bestFilter.put(type, new FilterScore(maxFilter, maxScore, atLimit));
					bestFilterOrder.add(type);
				}
				else
				{
					// Replace
					FilterScore filterScore = bestFilter.get(type);
					if (filterScore.score < maxScore)
						filterScore.update(maxFilter, maxScore, atLimit);
				}
			}
			else
			{
				bestFilter.put(type, new FilterScore(maxFilter, maxScore, atLimit));
				bestFilterOrder.add(type);
			}
		}

		// Add spacer at end of each result set
		if (isHeadless)
		{
			if (showResultsTable && filterSet.size() > 1)
				IJ.log("");
		}
		else
		{
			if (showResultsTable && filterSet.size() > 1)
				resultsWindow.append("");

			if (plotTopN > 0)
			{
				// Check the xValues are unique. Since the filters have been sorted by their
				// numeric value we only need to compare adjacent entries.
				boolean unique = true;
				for (int ii = 0; ii < xValues.length - 1; ii++)
				{
					if (xValues[ii] == xValues[ii + 1])
					{
						unique = false;
						break;
					}
				}
				String xAxisName = filterSet.getValueName();
				// Check the values all refer to the same property
				for (Filter filter : filterSet.getFilters())
				{
					if (!xAxisName.equals(filter.getNumericalValueName()))
					{
						unique = false;
						break;
					}
				}
				if (!unique)
				{
					// If not unique then renumber them and use an arbitrary label
					xAxisName = "Filter";
					for (int ii = 0; ii < xValues.length; ii++)
						xValues[ii] = ii + 1;
				}

				String title = filterSet.getName();

				// Check if a previous filter set had the same name, update if necessary
				NamedPlot p = getNamedPlot(title);
				if (p == null)
					plots.add(new NamedPlot(title, xAxisName, xValues, yValues));
				else
					p.updateValues(xAxisName, xValues, yValues);

				if (plots.size() > plotTopN)
				{
					Collections.sort(plots);
					p = plots.remove(plots.size() - 1);
				}
			}
		}

		return 0;
	}

	private String getDialogName(String prefix, String parameterName)
	{
		return prefix + parameterName.replace(" ", "_");
	}

	private double getCriteria(FractionClassificationResult s)
	{
		return getScore(s, criteriaIndex, invertCriteria);
	}

	private double getScore(FractionClassificationResult s)
	{
		return getScore(s, scoreIndex, invertScore);
	}

	private double getScore(FractionClassificationResult s, final int index, final boolean invert)
	{
		final double score = getScore(s, index);
		return (invert) ? -score : score;
	}

	private double getScore(FractionClassificationResult s, final int index)
	{
		// This order must match the COLUMNS order 
		switch (index)
		{
			case 0:
				return s.getTP() + s.getFP();
			case 1:
				return s.getTP();
			case 2:
				return s.getFP();
			case 3:
				return s.getTN();
			case 4:
				return s.getFN();
			case 5:
				return s.getTPR();
			case 6:
				return s.getTNR();
			case 7:
				return s.getPPV();
			case 8:
				return s.getNPV();
			case 9:
				return s.getFPR();
			case 10:
				return s.getFNR();
			case 11:
				return s.getFDR();
			case 12:
				return s.getAccuracy();
			case 13:
				return s.getMCC();
			case 14:
				return s.getInformedness();
			case 15:
				return s.getMarkedness();
			case 16:
				return s.getRecall();
			case 17:
				return s.getPrecision();
			case 18:
				return s.getF1Score();
			case 19:
				return s.getJaccard();
			case 20:
				return getOriginalScore(s).getFP();
			case 21:
				return getOriginalScore(s).getFN();
			case 22:
				return getOriginalScore(s).getRecall();
			case 23:
				return getOriginalScore(s).getPrecision();
			case 24:
				return getOriginalScore(s).getF1Score();
			case 25:
				return getOriginalScore(s).getJaccard();
		}
		return 0;
	}

	private boolean requiresInversion(final int index)
	{
		switch (index)
		{
			case 2: // FP
			case 4: // FN
			case 9: // FPR
			case 10: // FNR
			case 11: // FDR
			case 20: // oFP
			case 21: // oFN
				return true;

			default:
				return false;
		}
	}

	private NamedPlot getNamedPlot(String title)
	{
		for (NamedPlot p : plots)
			if (p.name.equals(title))
				return p;
		return null;
	}

	private double getMaximum(double[] values)
	{
		double max = values[0];
		for (int i = 1; i < values.length; i++)
		{
			if (values[i] > max)
			{
				max = values[i];
			}
		}
		return max;
	}

	private double[] run(Filter filter, List<MemoryPeakResults> resultsList, boolean subset, double tn, double fn, int n)
	{
		FractionClassificationResult r;
		if (subset)
		{
			r = filter.fractionScoreSubset(resultsList, failCount, tn, fn, n);

			//// DEBUG - Test if the two methods produce the same results
			//FractionClassificationResult r2 = scoreFilter(filter, BenchmarkFilterAnalysis.resultsList);
			//if (!gdsc.smlm.utils.DoubleEquality.almostEqualRelativeOrAbsolute(r.getTP(), r2.getTP(), 1e-6, 1e-10) ||
			//		!gdsc.smlm.utils.DoubleEquality.almostEqualRelativeOrAbsolute(r.getFP(), r2.getFP(), 1e-6, 1e-10) ||
			//		!gdsc.smlm.utils.DoubleEquality.almostEqualRelativeOrAbsolute(r.getTN(), r2.getTN(), 1e-6, 1e-10) ||
			//		!gdsc.smlm.utils.DoubleEquality.almostEqualRelativeOrAbsolute(r.getFN(), r2.getFN(), 1e-6, 1e-10))
			//{
			//	System.out.printf("TP %f != %f, FP %f != %f, TN %f != %f, FN %f != %f\n", r.getTP(), r2.getTP(),
			//			r.getFP(), r2.getFP(), r.getTN(), r2.getTN(), r.getFN(), r2.getFN());
			//}
		}
		else
			r = scoreFilter(filter, resultsList);

		//checkTotals(r.getTP(), r.getFP(), r.getTN(), r.getFN());

		final double score = getScore(r);
		final double criteria = getCriteria(r);

		// Show the result if it achieves the criteria limit 
		if (showResultsTable && criteria >= minCriteria)
		{
			String text = createResult(filter, r);

			if (isHeadless)
			{
				IJ.log(text);
			}
			else
			{
				resultsWindow.append(text);
			}
		}
		return new double[] { score, criteria };
	}

	/**
	 * Score the filter using the results list and the configured fail count
	 * 
	 * @param filter
	 * @param resultsList
	 * @return The score
	 */
	private FractionClassificationResult scoreFilter(Filter filter, List<MemoryPeakResults> resultsList)
	{
		double tp = 0, fp = 0, tn = 0, fn = 0;
		int p = 0, n = 0;
		for (int i = 0; i <= failCountRange; i++)
		{
			final FractionClassificationResult r = filter.fractionScore(resultsList, failCount + i);
			tp += r.getTP();
			fp += r.getFP();
			tn += r.getTN();
			fn += r.getFN();
			p += r.getPositives();
			n += r.getNegatives();
		}
		if (failCountRange == 0)
		{
			return new FractionClassificationResult(tp, fp, c_tn + tn, c_fn + fn, p, n);
		}
		// Normalise by the number of evaluations
		final int norm = failCountRange + 1;
		p = (int) Math.round((double) p / norm);
		n = (int) Math.round((double) n / norm);
		return new FractionClassificationResult(tp / norm, fp / norm, c_tn + tn / norm, c_fn + fn / norm, p, n);
	}

	public String createResult(Filter filter, FractionClassificationResult r)
	{
		StringBuilder sb = new StringBuilder(resultsPrefix);
		sb.append(filter.getName()).append(resultsPrefix2).append(resultsPrefix3);

		int i = 0;

		addCount(sb, r.getTP() + r.getFP(), i++);
		addCount(sb, r.getTP(), i++);
		addCount(sb, r.getFP(), i++);
		addCount(sb, r.getTN(), i++);
		addCount(sb, r.getFN(), i++);

		add(sb, r.getTPR(), i++);
		add(sb, r.getTNR(), i++);
		add(sb, r.getPPV(), i++);
		add(sb, r.getNPV(), i++);
		add(sb, r.getFPR(), i++);
		add(sb, r.getFNR(), i++);
		add(sb, r.getFDR(), i++);
		add(sb, r.getAccuracy(), i++);
		add(sb, r.getMCC(), i++);
		add(sb, r.getInformedness(), i++);
		add(sb, r.getMarkedness(), i++);

		add(sb, r.getRecall(), i++);
		add(sb, r.getPrecision(), i++);
		add(sb, r.getF1Score(), i++);
		add(sb, r.getJaccard(), i++);

		// Score relative to the original simulated number of spots
		FractionClassificationResult m = getOriginalScore(r);
		addCount(sb, m.getFP(), i++);
		addCount(sb, m.getFN(), i++);
		add(sb, m.getRecall(), i++);
		add(sb, m.getPrecision(), i++);
		add(sb, m.getF1Score(), i++);
		add(sb, m.getJaccard(), i++);
		return sb.toString();
	}

	private FractionClassificationResult getOriginalScore(FractionClassificationResult r)
	{
		// Score the fitting results against the original simulated data:
		// TP are all fit results that can be matched to a spot
		// FP are all fit results that cannot be matched to a spot
		// FN are the number of missed spots
		// Note: We cannot calculate TN since this is the number of fit candidates that are 
		// filtered after fitting that do not match a spot or were not fitted. 
		final double fp = r.getPositives() - r.getTP();
		final double fn = simulationParameters.molecules - r.getTP();
		return new FractionClassificationResult(r.getTP(), fp, 0, fn);
	}

	private static void add(StringBuilder sb, String value)
	{
		sb.append("\t").append(value);
	}

	@SuppressWarnings("unused")
	private static void add(StringBuilder sb, int value, int i)
	{
		if (showColumns[i])
			sb.append("\t").append(value);
	}

	private static void addCount(StringBuilder sb, double value, int i)
	{
		if (showColumns[i])
		{
			// Check if the double holds an integer count
			if ((int) value == value)
			{
				sb.append("\t").append((int) value);
			}
			else
			{
				// Otherwise add the counts using at least 2 dp
				if (value > 100)
					sb.append("\t").append(IJ.d2s(value));
				else
					add(sb, Utils.rounded(value));
			}
		}
	}

	private static void add(StringBuilder sb, double value, int i)
	{
		if (showColumns[i])
			add(sb, Utils.rounded(value));
	}

	private void saveFilter(Filter filter)
	{
		// Save the filter to file
		String filename = getFilename("Best_Filter_File", filterFilename);
		if (filename != null)
		{
			filterFilename = filename;

			List<Filter> filters = new LinkedList<Filter>();
			filters.add(filter);
			FilterSet filterSet = new FilterSet(filter.getName(), filters);
			List<FilterSet> list = new LinkedList<FilterSet>();
			list.add(filterSet);
			saveFilterSet(filterSet, filename);
		}
	}

	private static String getFilename(String title, String filename)
	{
		filename = Utils.getFilename(title, filename);
		// Use XML extension
		if (filename != null)
			filename = Utils.replaceExtension(filename, ".xml");
		return filename;
	}

	private static void saveFilterSet(FilterSet filterSet, String filename)
	{
		OutputStreamWriter out = null;
		try
		{
			List<FilterSet> list = new LinkedList<FilterSet>();
			list.add(filterSet);
			FileOutputStream fos = new FileOutputStream(filename);
			out = new OutputStreamWriter(fos, "UTF-8");
			out.write(XmlUtils.prettyPrintXml(XmlUtils.toXML(list)));
		}
		catch (Exception e)
		{
			IJ.log("Unable to save the filter sets to file: " + e.getMessage());
		}
		finally
		{
			if (out != null)
			{
				try
				{
					out.close();
				}
				catch (IOException e)
				{
					// Ignore
				}
			}
		}
	}

	/**
	 * Save the filter set to a file prompted from the user
	 * 
	 * @param filterSet
	 * @param setNumber
	 */
	private void saveFilterSet(FilterSet filterSet, int setNumber)
	{
		stopTimer();

		String filename = getFilename("Filter_set_" + setNumber, filterSetFilename);
		if (filename != null)
		{
			filterSetFilename = filename;
			saveFilterSet(filterSet, filename);
		}

		startTimer();
	}

	/**
	 * @param filter
	 */
	private void depthAnalysis(Filter filter)
	{
		// TODO : This analysis ignores the partial match distance.
		// Use the score for each result to get a weighted histogram. 

		if (!depthRecallAnalysis || simulationParameters.fixedDepth)
			return;

		// Build a histogram of the number of spots at different depths
		final double[] depths = depthStats.getValues();
		final double range = simulationParameters.depth / simulationParameters.a / 2;
		double[] limits = { -range, range };

		final int bins = Math.max(10, simulationParameters.molecules / 100);
		double[][] h1 = Utils.calcHistogram(depths, limits[0], limits[1], bins);
		double[][] h2 = Utils.calcHistogram(depthFitStats.getValues(), limits[0], limits[1], bins);

		// To get the number of TP at each depth will require that the filter is run 
		// manually to get the results that pass.
		MemoryPeakResults results = filter.filter(resultsList.get(0), failCount);

		double[] depths2 = new double[results.size()];
		int count = 0;
		for (PeakResult r : results.getResults())
		{
			if (r.origValue != 0)
				depths2[count++] = ((DepthPeakResult) r).depth;
		}
		depths2 = Arrays.copyOf(depths2, count);

		// Build a histogram using the same limits
		double[][] h3 = Utils.calcHistogram(depths2, limits[0], limits[1], bins);

		// Convert pixel depth to nm
		for (int i = 0; i < h1[0].length; i++)
			h1[0][i] *= simulationParameters.a;
		limits[0] *= simulationParameters.a;
		limits[1] *= simulationParameters.a;

		// Produce a histogram of the number of spots at each depth
		String title = TITLE + " Depth Histogram";
		Plot2 plot = new Plot2(title, "Depth (nm)", "Frequency");
		plot.setLimits(limits[0], limits[1], 0, Maths.max(h1[1]));
		plot.setColor(Color.black);
		plot.addPoints(h1[0], h1[1], Plot2.BAR);
		plot.addLabel(0, 0, "Black = Spots; Blue = Fitted; Red = Filtered");
		plot.setColor(Color.blue);
		plot.addPoints(h1[0], h2[1], Plot2.BAR);
		plot.setColor(Color.red);
		plot.addPoints(h1[0], h3[1], Plot2.BAR);
		plot.setColor(Color.magenta);
		PlotWindow pw = Utils.display(title, plot);

		// Interpolate
		final double halfBinWidth = (h1[0][1] - h1[0][0]) * 0.5;
		// Remove final value of the histogram as this is at the upper limit of the range (i.e. count zero)
		h1[0] = Arrays.copyOf(h1[0], h1[0].length - 1);
		h1[1] = Arrays.copyOf(h1[1], h1[0].length);
		h2[1] = Arrays.copyOf(h2[1], h1[0].length);
		h3[1] = Arrays.copyOf(h3[1], h1[0].length);

		// TODO : Fix the smoothing since LOESS sometimes does not work.
		// Perhaps allow configuration of the number of histogram bins and the smoothing bandwidth.

		// Use minimum of 3 points for smoothing
		// Ensure we use at least x% of data
		double bandwidth = Math.max(3.0 / h1[0].length, 0.15);
		LoessInterpolator loess = new LoessInterpolator(bandwidth, 1);
		PolynomialSplineFunction spline1 = loess.interpolate(h1[0], h1[1]);
		PolynomialSplineFunction spline2 = loess.interpolate(h1[0], h2[1]);
		PolynomialSplineFunction spline3 = loess.interpolate(h1[0], h3[1]);
		// Use a second interpolator in case the LOESS fails
		LinearInterpolator lin = new LinearInterpolator();
		PolynomialSplineFunction spline1b = lin.interpolate(h1[0], h1[1]);
		PolynomialSplineFunction spline2b = lin.interpolate(h1[0], h2[1]);
		PolynomialSplineFunction spline3b = lin.interpolate(h1[0], h3[1]);

		// Increase the number of points to show a smooth curve
		double[] points = new double[bins * 5];
		limits = Maths.limits(h1[0]);
		final double interval = (limits[1] - limits[0]) / (points.length - 1);
		double[] v = new double[points.length];
		double[] v2 = new double[points.length];
		double[] v3 = new double[points.length];
		for (int i = 0; i < points.length - 1; i++)
		{
			points[i] = limits[0] + i * interval;
			v[i] = getSplineValue(spline1, spline1b, points[i]);
			v2[i] = getSplineValue(spline2, spline2b, points[i]);
			v3[i] = getSplineValue(spline3, spline3b, points[i]);
			points[i] += halfBinWidth;
		}
		// Final point on the limit of the spline range
		int ii = points.length - 1;
		v[ii] = getSplineValue(spline1, spline1b, limits[1]);
		v2[ii] = getSplineValue(spline2, spline2b, limits[1]);
		v3[ii] = getSplineValue(spline3, spline3b, limits[1]);
		points[ii] = limits[1] + halfBinWidth;

		// Calculate recall
		for (int i = 0; i < v.length; i++)
		{
			v2[i] = v2[i] / v[i];
			v3[i] = v3[i] / v[i];
		}

		final double halfSummaryDepth = summaryDepth * 0.5;

		title = TITLE + " Depth Histogram (normalised)";
		plot = new Plot2(title, "Depth (nm)", "Recall");
		plot.setLimits(limits[0] + halfBinWidth, limits[1] + halfBinWidth, 0, Maths.min(1, Maths.max(v2)));
		plot.setColor(Color.black);
		plot.addLabel(0, 0, "Blue = Fitted; Red = Filtered");
		plot.setColor(Color.blue);
		plot.addPoints(points, v2, Plot2.LINE);
		plot.setColor(Color.red);
		plot.addPoints(points, v3, Plot2.LINE);
		plot.setColor(Color.magenta);
		plot.drawLine(
				-halfSummaryDepth,
				0,
				-halfSummaryDepth,
				getSplineValue(spline3, spline3b, -halfSummaryDepth - halfBinWidth) /
						getSplineValue(spline1, spline1b, -halfSummaryDepth - halfBinWidth));
		plot.drawLine(
				halfSummaryDepth,
				0,
				halfSummaryDepth,
				getSplineValue(spline3, spline3b, halfSummaryDepth - halfBinWidth) /
						getSplineValue(spline1, spline1b, halfSummaryDepth - halfBinWidth));
		PlotWindow pw2 = Utils.display(title, plot);
		if (Utils.isNewWindow())
		{
			Point p = pw.getLocation();
			p.y += pw.getHeight();
			pw2.setLocation(p);
		}
	}

	private double getSplineValue(PolynomialSplineFunction spline, PolynomialSplineFunction spline2, double x)
	{
		double y = spline.value(x);
		if (Double.isNaN(y))
			y = spline2.value(x);
		return y;
	}

	public class FilterScore implements Comparable<FilterScore>
	{
		Filter filter;
		double score;
		boolean atLimit;

		public FilterScore(Filter filter, double scorem, boolean atLimit)
		{
			update(filter, score, atLimit);
		}

		public void update(Filter filter, double score, boolean atLimit)
		{
			this.filter = filter;
			this.score = score;
			this.atLimit = atLimit;
		}

		public int compareTo(FilterScore that)
		{
			if (this.score > that.score)
				return -1;
			if (this.score < that.score)
				return 1;
			return 0;
		}
	}

	public class NamedPlot implements Comparable<NamedPlot>
	{
		String name, xAxisName;
		double[] xValues, yValues;
		double score;

		public NamedPlot(String name, String xAxisName, double[] xValues, double[] yValues)
		{
			this.name = name;
			updateValues(xAxisName, xValues, yValues);
		}

		public void updateValues(String xAxisName, double[] xValues, double[] yValues)
		{
			this.xAxisName = xAxisName;
			this.xValues = xValues;
			this.yValues = yValues;
			this.score = getMaximum(yValues);
		}

		public int compareTo(NamedPlot o)
		{
			if (score > o.score)
				return -1;
			if (score < o.score)
				return 1;
			return 0;
		}
	}

	private class DepthPeakResult extends PeakResult
	{
		final double depth, matchScore, noMatchScore;

		public DepthPeakResult(int peak, int origX, int origY, float score, double error, float noise, float[] params,
				double depth, double matchScore, double noMatchScore)
		{
			super(peak, origX, origY, score, error, noise, params, null);
			this.depth = depth;
			this.matchScore = matchScore;
			this.noMatchScore = noMatchScore;
		}

		@Override
		public double getTruePositiveScore()
		{
			return matchScore;
		}

		@Override
		public double getFalsePositiveScore()
		{
			return noMatchScore;
		};

		@Override
		public double getTrueNegativeScore()
		{
			return noMatchScore;
		}

		@Override
		public double getFalseNegativeScore()
		{
			return matchScore;
		}
	}

	/**
	 * Allow the genetic algorithm to be stopped using the escape key
	 */
	private class InterruptChecker extends ToleranceChecker
	{
		final int convergedCount;
		int count = 0;

		public InterruptChecker(double relative, double absolute, int convergedCount)
		{
			super(relative, absolute);
			this.convergedCount = convergedCount;
		}

		@Override
		public boolean converged(Chromosome previous, Chromosome current)
		{
			if (super.converged(previous, current))
				count++;
			else
				count = 0;
			// Allow no convergence except when escape is pressed
			if (convergedCount >= 0 && count > convergedCount)
				return true;
			if (IJ.escapePressed())
			{
				Utils.log("STOPPED " + ga_statusPrefix);
				IJ.resetEscape(); // Allow the plugin to continue processing
				return true;
			}
			return false;
		}
	}

	// Used to implement the FitnessFunction interface 
	private String ga_statusPrefix;
	private Population ga_population;

	// Used for the scoring of filter sets
	private List<MemoryPeakResults> ga_resultsList = null;
	private List<MemoryPeakResults> ga_resultsListToScore = null;
	private double ga_tn, ga_fn;
	private int ga_n;
	private boolean ga_subset;
	private int ga_iteration;

	/*
	 * (non-Javadoc)
	 * 
	 * @see gdsc.smlm.ga.FitnessFunction#initialise(java.util.List)
	 */
	public void initialise(List<? extends Chromosome> individuals)
	{
		ga_iteration++;
		//updateGAStatus();
		initialiseScoring(new FilterSet(populationToFilters(individuals)));
	}

	public ArrayList<Filter> populationToFilters(List<? extends Chromosome> individuals)
	{
		ArrayList<Filter> filters = new ArrayList<Filter>(individuals.size());
		for (Chromosome c : individuals)
			filters.add((Filter) c);
		return filters;
	}

	/**
	 * Initialise the results list used for scoring the filters. This is shared with the genetic algorithm.
	 * 
	 * @param filterSet
	 */
	private void initialiseScoring(FilterSet filterSet)
	{
		// Initialise with the candidate true and false negative scores
		ga_tn = c_tn;
		ga_fn = c_fn;
		ga_n = 0;
		ga_resultsListToScore = ga_resultsList;
		ga_subset = false;

		if (filterSet.size() < 2)
			return;

		if (failCountRange == 0)
		{
			Filter weakest = filterSet.createWeakestFilter();
			if (weakest != null)
			{
				ga_subset = true;
				ga_resultsListToScore = new ArrayList<MemoryPeakResults>(ga_resultsList.size());
				double[] score = null;
				// Some filters may require all the data, e.g. Hysteresis filters
				final boolean withFailCount = weakest.subsetWithFailCount();
				for (MemoryPeakResults r : ga_resultsList)
				{
					double[] score2 = new double[6];
					MemoryPeakResults r2 = (withFailCount) ? weakest.filterSubset(r, failCount, score2) : weakest
							.filterSubset(r, score2);
					ga_resultsListToScore.add(r2);
					if (score == null)
						score = score2;
					else
					{
						for (int j = 0; j < score.length; j++)
							score[j] += score2[j];
					}
				}
				ga_tn += score[2];
				ga_fn += score[3];
				ga_n += score[5];

				checkTotals(ga_resultsListToScore.get(0), ga_tn, ga_fn);
			}
		}
	}

	/*
	 * (non-Javadoc)
	 * 
	 * @see gdsc.smlm.ga.FitnessFunction#fitness(gdsc.smlm.ga.Chromosome)
	 */
	public double fitness(Chromosome chromosome)
	{
		Filter filter = (Filter) chromosome;
		FractionClassificationResult r;
		if (ga_subset)
			r = filter.fractionScoreSubset(ga_resultsListToScore, failCount, ga_tn, ga_fn, ga_n);
		else
			r = scoreFilter(filter, ga_resultsListToScore);
		double score = getScore(r);
		final double criteria = getCriteria(r);

		if (strictFitness)
		{
			// No fitness for those below the criteria 
			if (criteria < minCriteria)
				score = 0;
		}
		else
		{
			// Make sure all individuals who pass the criteria are above those that do not.
			// This will work unless we are scoring using the counts (i.e. scores that may exceed 1) 
			if (criteria >= minCriteria)
				score += 1;
		}

		return score;
	}

	/*
	 * (non-Javadoc)
	 * 
	 * @see gdsc.smlm.ga.FitnessFunction#shutdown()
	 */
	public void shutdown()
	{
		// Report the score for the best filter
		List<? extends Chromosome> individuals = ga_population.getIndividuals();
		ChromosomeComparator.sort(individuals);

		Filter filter = (Filter) individuals.get(0);

		// This filter may not have been part of the scored subset so use the entire results set for reporting
		FractionClassificationResult r = scoreFilter(filter, ga_resultsList);

		String text = createResult(filter, r);
		gaWindow.append(text + "\t" + ga_iteration);
	}

	double limit = 0;

	public void progress(double fraction)
	{
		if (fraction == 1)
		{
			// Reset
			limit = 0;
			IJ.showProgress(fraction);
			return;
		}

		// Show only 2% changes
		if (fraction < limit)
			return;

		limit = fraction + 0.02;
		IJ.showProgress(fraction);
	}

	public void progress(long position, long total)
	{
		progress((double) position / total);
	}

	public void log(String format, Object... args)
	{
		// Ignore		
	}

	public void status(String format, Object... args)
	{
		IJ.showStatus(ga_statusPrefix + String.format(format, args));
	}

	public boolean isEnded()
	{
		// Ignore		
		return false;
	}
}
